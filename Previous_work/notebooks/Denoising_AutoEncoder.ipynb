{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"12.Denoising_AutoEncoder.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1OtiZlirdu3LW2B199nGKLYUCjPYEMaFM","authorship_tag":"ABX9TyNl92GGn6edH+IYUQ54vxEr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","collapsed":true,"id":"k4afOr3z3GJN","executionInfo":{"status":"ok","timestamp":1656952323052,"user_tz":420,"elapsed":10297,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"5ec6ce81-3765-4bdc-c73c-9abd27ac9195"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.17.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboard-plugin-profile\n","  Downloading tensorboard_plugin_profile-2.8.0-py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 596 kB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-plugin-profile) (1.15.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-plugin-profile) (57.4.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-plugin-profile) (3.17.3)\n","Collecting gviz-api>=1.9.0\n","  Downloading gviz_api-1.10.0-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard-plugin-profile) (1.0.1)\n","Installing collected packages: gviz-api, tensorboard-plugin-profile\n","Successfully installed gviz-api-1.10.0 tensorboard-plugin-profile-2.8.0\n"]}],"source":["#@title\n","!pip install tensorflow-addons\n","!pip install -U tensorboard-plugin-profile"]},{"cell_type":"markdown","source":["# Intro\n","After some research I found denoising autoencoders can do really well at missing data imputation. I have also never made one so I decided to give it a go! Adaptations for missing values were implimentated from [this](https://arxiv.org/abs/2002.08338) paper. Soem key takeaways from the paper are:\n","- All data are used for training since there is no need for a validation or test set\n","- DAEs are sensitive to initial imputation, this is addressed using metamorphic truth and feedback. In the first step the imputed values (and all other values in the row) are used as ground truth for the optimizer, which is obviously a problem. So, metamorphic truth takes the predicted value to use as ground truth for the next step while feedback uses the predicted values instead of the original imputed value as input.\n","- Training is split into two stages: First stage has no feedback, so the inputs for missing values are just the original imputation (paper suggests 10-20 epochs). Then it is 'fine tuned' using the afforementioned feeback every *n* steps (paper suggests 1-2)."],"metadata":{"id":"g3EwBE703seM"}},{"cell_type":"markdown","source":["# Importing Libraries"],"metadata":{"id":"vUeSC-JTGjiK"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import random\n","import math\n","import yaml\n","import pickle\n","from tqdm.notebook import tqdm\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import KFold, train_test_split\n","\n","import datetime\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend as K, layers\n","from tensorflow.keras.layers import Dense, Input, InputLayer, Add, BatchNormalization, Dropout\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n","from tensorflow.keras.utils import plot_model\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' ## hide tf warnings\n","\n","from drive.MyDrive.Kaggle.June_2022_na_imputation.src.functions import *"],"metadata":{"id":"UB96GU0oDdHz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('/content/drive/MyDrive/Kaggle/June_2022_na_imputation/src/data/data.csv', index_col='row_id')\n","sample = pd.read_csv('/content/drive/MyDrive/Kaggle/June_2022_na_imputation/src/data/sample_submission.csv', index_col='row-col')"],"metadata":{"id":"rlAP5X0oGsHi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/Kaggle/June_2022_na_imputation/src/config.YAML', 'r') as f:\n","    config = yaml.load(f)\n","\n","set_seed(config['SEED'])\n","col_list, F1, F2, F3, F4, missing_cols = get_lists(data)"],"metadata":{"id":"IVVUFg8sGyxj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir logs/fit"],"metadata":{"id":"hEsBw93KGzsm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Defining Masks"],"metadata":{"id":"9_04MzADbU1B"}},{"cell_type":"code","source":["def random_masking(shape, binomial_P=0.05):\n","    # create dimensions and an array the size of your dataset for masking\n","    n, k = shape\n","    mask = np.ones(shape)\n","    # create minimum one mask per row\n","    mask[(\n","        np.arrange(n),\n","        np.random.randint(0, k, n)\n","    )] = 0\n","    # add binomial probability\n","    binomial_mask = np.random.binomial(1, 1 - binomial_P, (n, k))\n","    return mask * binomial_mask\n","\n","def validation_mask(shape, n_missing):\n","    # create a mask for validation with set # of missing values per row\n","    n, k = shape\n","    s = np.arrange(k)[np.newaxis, :].repeat(n).reshape(n, k)\n","    idx = np.random.randint(n, k).argsort(1)[:, :n_missing]\n","    col_idx = np.take_along_axis(s, idx, axis=1).ravel()\n","    row_idx = np.arrange(n).repeat(n_missing)\n","\n","    mask = np.ones((n, k))\n","    mask[(\n","        row_idx,\n","        col_idx\n","    )] = 0\n","    return mask"],"metadata":{"id":"WeEfmubbGzkM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Defining Datasets"],"metadata":{"id":"_2Y8OoXXbPWT"}},{"cell_type":"code","source":["nan_bool = data[F4].isna().sum(axis=1) > 0\n","\n","X_nonan = data.loc[~nan_bool, F4].values\n","X_nan = data.loc[nan_bool, F4].values\n","\n","X_train_nonan, X_val = train_test_split(X_nonan)\n","\n","X_train = np.concatenate([X_train_nonan, X_nan], axis=0)\n","\n","nan_source = np.concatenate([\n","                             np.zeros(X_train_nonan.shape),\n","                             data.loc[nan_bool, F4].isna().astype(np.uint8).values\n","])\n","\n","scaler = StandardScaler()\n","X_train = np.nan_to_num(scaler.fit_transform(X_train), 0)\n","X_val = scaler.transform(X_val)"],"metadata":{"id":"SEkKWHxJGzf4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Defining Network"],"metadata":{"id":"uyUeQ4K8fJwM"}},{"cell_type":"code","source":["np.array([-1, 0, 1, 5]).astype(np.bool_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ss60RF6QGzVx","executionInfo":{"status":"ok","timestamp":1656962066305,"user_tz":420,"elapsed":151,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"094f74df-ce01-4756-e0d7-a76f55fa6731"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ True, False,  True,  True])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["def rmse(y_true, y_pred):\n","    return K.sqrt(K.mean(K.square(y_pred - y_true)))"],"metadata":{"id":"6ONCSNdFF8by"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MLP(layers.Layer):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.dense = Dense(input_size)"],"metadata":{"id":"6e9KaGPJ6OWX"},"execution_count":null,"outputs":[]}]}